# YOLOv8

[GitHub - ultralytics/ultralytics: NEW - YOLOv8 ğŸš€ in PyTorch > ONNX > CoreML > TFLite](https://github.com/ultralytics/ultralytics)

[TOC]



## ç¯å¢ƒé…ç½®

### Anaconda

 åˆ›å»ºanacondaè™šæ‹Ÿç¯å¢ƒ

```
conda create -n pyhton3.10 python=3.10
conda activate 
```

### pytorchå’Œtorchvision

[PyTorch](https://pytorch.org/)

åœ¨pytorchå®˜ç½‘æŸ¥æ‰¾cudaç‰ˆæœ¬å¯¹åº”çš„pipæˆ–condaæŒ‡ä»¤ï¼Œå¦‚æœä¸éœ€è¦GPUè®­ç»ƒå’Œé¢„æµ‹ï¼Œç›´æ¥pipæˆ–condaä¹Ÿå¯ä»¥

```
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
```

### YOLOv8(ultralytics)

[GitHub - ultralytics/ultralytics: NEW - YOLOv8 ğŸš€ in PyTorch > ONNX > CoreML > TFLite](https://github.com/ultralytics/ultralytics)

è¿™é‡Œå»ºè®®ä½¿ç”¨

```
git clone https://github.com/ultralytics/ultralytics
```

ç›´æ¥zipä¸‹è½½å®‰è£…ä¼šå¯¼è‡´è¿è¡Œæ—¶å‡ºç°æŠ¥é”™

```
ImportError: Bad git executable
```

åœ¨ultralyticsï¼ˆç¬¬ä¸€ä¸ªï¼‰ç›®å½•ä¸‹

é€šè¿‡pipå®‰è£…requirements

```
pip install -r requirements.txt
```

ï¼ˆæ³¨æ„ï¼šè¿™é‡Œç›´æ¥å®‰è£…çš„Pillowç‰ˆæœ¬è¿‡é«˜å¯èƒ½å¯¼è‡´é”™è¯¯ï¼Œæˆ‘æ‰‹åŠ¨é™åˆ°Pillow=9.2.0ã€‚å¦‚æœç”¨AutoDLï¼Œç¯å¢ƒéƒ½æ˜¯é…å¥½çš„ï¼Œç›´æ¥ç”¨å°±å¯ä»¥ã€‚ï¼‰

## æ•°æ®å‡†å¤‡

### YOLOv8è‡ªå¸¦æ•°æ®

è®­ç»ƒæ—¶ä¸æ³¨æ˜å…·ä½“çš„data.yamlæ–‡ä»¶ï¼ˆæˆ–æ˜¯ä½¿ç”¨'coco128.yaml'ï¼‰ï¼Œåˆ™ä¼šè‡ªåŠ¨åœ¨githubä¸‹è½½æ•°æ®é›†ã€‚é»˜è®¤æ•°æ®é›†å¾ˆå¤§ï¼Œgithubæ²¡æœ‰ç§‘å­¦ä¸Šç½‘ä¸‹è½½å¾ˆæ…¢ã€‚ï¼ˆğŸ˜­æˆ‘â„¢30ä¸ªGçš„æ¢¯å­æµé‡ï¼‰

coco128è¿™ä¸ªæ•°æ®é›†ä¸æ˜¯å¾ˆå¤§ã€‚

### roboflowæ•°æ®é›†

[Roboflow](https://app.roboflow.com/)

roboflowæ˜¯ä¸€ä¸ªå¾ˆå¥½ç”¨çš„æ ‡è®°æ•°æ®çš„ç½‘ç«™ã€‚åˆ›å»ºé¡¹ç›®åè‡ªå·±ä¸Šä¼ æ•°æ®å›¾ç‰‡ï¼Œæ·»åŠ æ ‡è®°ä¹‹åå°±å¯ä»¥å¼€å§‹æ ‡æ³¨ã€‚

![image-20230713115104273](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713115104273.png)

é€‰æ‹©æ–‡ä»¶æˆ–è€…æ–‡ä»¶å¤¹ä¸Šä¼ å›¾ç‰‡ => é€‰æ‹©Save and Continueç»§ç»­ => é€‰æ‹©å›¢é˜Ÿå†…æˆå‘˜åˆ†é…å·¥ä½œ

å¼€å§‹æ ‡æ³¨

![image-20230713141000137](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713141000137.png)

æ ‡æ³¨å®Œæˆåæ·»åŠ åˆ°æ•°æ®åº“ä¸­ï¼Œroboflowä¼šè‡ªåŠ¨å¯¹æ•°æ®åˆ†ç±»ã€‚

![image-20230713141131295](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713141131295.png)

æœ€ååœ¨generateä¸­å¯¼å‡ºè®­ç»ƒæ•°æ®ã€‚è¿™é‡Œå¯ä»¥é€‰æ‹©å¯¹æ•°æ®é›†å›¾ç‰‡è¿›è¡Œresizeç­‰é¢„å¤„ç†ï¼ŒYOLOv8æ–‡æ¡£é‡Œæ¨èä½¿ç”¨çš„æ˜¯Auto-Orientï¼Œå’Œ640*640çš„resizeã€‚

![image-20230713141255580](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713141255580.png)



æœ€åé€‰æ‹©ç”Ÿæˆï¼Œé€‰æ‹©Export Datasetå¯¼å‡ºã€‚

![image-20230713141743467](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713141743467.png)

è¿™é‡Œæä¾›ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§ç›´æ¥ä¸‹è½½ï¼Œä¸€ç§ç”¨pythonä»£ç ä¸‹è½½ï¼ˆéœ€è¦pip install roboflowï¼‰ã€‚ä»£ç ä¸‹è½½åœ¨JupyterLabä¸­ä½¿ç”¨æ›´æ–¹ä¾¿ã€‚

![image-20230713144356838](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713144356838.png)

ä¸‹è½½å‹ç¼©åŒ…åè§£å‹ï¼Œæ–‡ä»¶å¤¹ä¸­æœ‰è¿™äº›æ–‡ä»¶ã€‚

## è®­ç»ƒ

YOLOv8æä¾›äº†ä¸¤ç§ä½¿ç”¨æ¨¡å‹çš„æ–¹æ³•ï¼Œä¸€ç§é€šè¿‡CLIï¼Œå¦ä¸€ç§é€šè¿‡Pythonä»£ç ã€‚è¿™é‡Œæˆ‘ä½¿ç”¨çš„Pythonä»£ç çš„æ–¹æ³•ã€‚

YOLOv8å¯ä»¥è¿›è¡Œæ£€æµ‹ï¼ˆdetectionï¼‰ï¼Œåˆ†å‰²ï¼ˆsegmentationï¼‰ï¼Œåˆ†ç±»ï¼ˆclassificationï¼‰ã€‚è¿™é‡Œåªè®²detectionã€‚

é¦–å…ˆéœ€è¦å¯¼å…¥YOLO

```python
from ultralytics import YOLO
```

é€‰æ‹©ä¸€ä¸ªé¢„è®­ç»ƒçš„æ¨¡å‹å¯¼å…¥

```python
model = YOLO('yolov8n.pt')
```

è¿™é‡Œæœ‰å¤šä¸ªä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œé‡Œé¢çš„å‚æ•°ä¸åŒã€‚æ¨¡å‹çš„åŒºåˆ«å…·ä½“è¡¨ç°åœ¨æ€§èƒ½å’Œç²¾åº¦ä¸Šã€‚æ€§èƒ½æ›´å¥½çš„ç²¾åº¦å°±è¾ƒå·®ã€‚ä¸‹è¡¨ä¸ºå„ä¸ªæ¨¡å‹çš„æ€§èƒ½è¡¨ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©ã€‚

![image-20230713143227506](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713143227506.png)

å¯¼å…¥æ¨¡å‹åï¼Œå¼€å§‹è®­ç»ƒ

```python
model.train(data="data.yaml", epochs=100)
```

è¿™é‡Œæœ‰å¾ˆå¤šå‚æ•°ï¼Œå…·ä½“å¯ä»¥åœ¨æ–‡æ¡£ç½‘ç«™ä¸­æŸ¥çœ‹ï¼Œè¿™é‡Œæˆ‘åªåˆ—ä¸¾å‡ ä¸ªã€‚

[Train - Ultralytics YOLOv8 Docs](https://docs.ultralytics.com/modes/train/#arguments)

|   Key    | Value  |                         Description                          |
| :------: | :----: | :----------------------------------------------------------: |
|   data   |  None  |             path to data file, i.e. coco128.yaml             |
|  epochs  |  100   |                number of epochs to train for                 |
| `batch`  |  `16`  |        number of images per batch (-1 for AutoBatch)         |
| `device` | `None` | device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu |
|  `save`  | `True` |          save train checkpoints and predict results          |

å¦‚æœæ˜¯é€‰æ‹©ç”¨è‡ªå·±çš„æ•°æ®ï¼Œåˆ™ç›´æ¥æŠŠdataè®¾ç½®æˆä»roboflowä¸‹è½½çš„æ–‡ä»¶å¤¹é‡Œçš„'data.yaml'ã€‚è®­ç»ƒè®¾å¤‡é»˜è®¤ä½¿ç”¨CPUï¼Œè¦é€‰æ‹©GPUè®­ç»ƒï¼Œå¿…é¡»å®‰è£…äº†cudaä»¥åŠGPUç‰ˆæœ¬çš„pytorchã€‚åœ¨è¿™é‡Œè®¾ç½®device = 0å³å¯ä½¿ç”¨GPUè®­ç»ƒã€‚å¦‚æœå¤šGPUè®­ç»ƒï¼Œè®¾ç½®ä¾‹å¦‚device = [0,1,2]ã€‚

è®­ç»ƒå®Œæˆåï¼Œè®­ç»ƒæ¨¡å‹ä¿å­˜åœ¨ /runs/detect ç›®å½•ä¸­ï¼Œåå­—ä¸ºtrainã€‚trainä¸­ä¿å­˜äº†æœ¬æ¬¡è®­ç»ƒçš„è®­ç»ƒè¿‡ç¨‹å›¾ç¤ºï¼Œä»¥åŠå„ç±»æ•°æ®ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°ä¸€äº›éªŒè¯ç»“æœã€‚

![val_batch2_pred](F:\yolov8\ultralytics\runs\detect\defult\val_batch2_pred.jpg)

å…¶ä¸­ï¼Œweightsæ–‡ä»¶å¤¹ä¸­çš„ä¸¤ä¸ªptæ–‡ä»¶ï¼Œbest.pt å’Œ last.ptï¼Œæ˜¯è®­ç»ƒæ¨¡å‹æœ¬ä½“ã€‚åç»­éªŒè¯æˆ–é¢„æµ‹éœ€è¦ç”¨åˆ°ã€‚

## éªŒè¯

è¿™é‡Œçš„'best.pt'è¦ç”¨åˆšæ‰è®­ç»ƒå®Œæˆçš„æ¨¡å‹æœ¬ä½“ã€‚

```python
from ultralytics import YOLO

model = YOLO('best.pt')
model.val()
```

## é¢„æµ‹

é¢„æµ‹çš„è¾“å…¥æ–‡ä»¶å¯ä»¥æ˜¯å›¾ç‰‡ã€URLã€è§†é¢‘ã€æˆªå±ç­‰ç­‰ã€‚

| Source      | Argument                                   | Type                                  | Notes                                                        |
| ----------- | ------------------------------------------ | ------------------------------------- | ------------------------------------------------------------ |
| image       | `'image.jpg'`                              | `str` or `Path`                       | Single image file.                                           |
| URL         | `'https://ultralytics.com/images/bus.jpg'` | `str`                                 | URL to an image.                                             |
| screenshot  | `'screen'`                                 | `str`                                 | Capture a screenshot.                                        |
| PIL         | `Image.open('im.jpg')`                     | `PIL.Image`                           | HWC format with RGB channels.                                |
| OpenCV      | `cv2.imread('im.jpg')`                     | `np.ndarray` of `uint8 (0-255)`       | HWC format with BGR channels.                                |
| numpy       | `np.zeros((640,1280,3))`                   | `np.ndarray` of `uint8 (0-255)`       | HWC format with BGR channels.                                |
| torch       | `torch.zeros(16,3,320,640)`                | `torch.Tensor` of `float32 (0.0-1.0)` | BCHW format with RGB channels.                               |
| CSV         | `'sources.csv'`                            | `str` or `Path`                       | CSV file containing paths to images, videos, or directories. |
| video âœ…     | `'video.mp4'`                              | `str` or `Path`                       | Video file in formats like MP4, AVI, etc.                    |
| directory âœ… | `'path/'`                                  | `str` or `Path`                       | Path to a directory containing images or videos.             |
| glob âœ…      | `'path/*.jpg'`                             | `str`                                 | Glob pattern to match multiple files. Use the `*` character as a wildcard. |
| YouTube âœ…   | `'https://youtu.be/Zgi9g1ksQHc'`           | `str`                                 | URL to a YouTube video.                                      |
| stream âœ…    | `'rtsp://example.com/media.mp4'`           | `str`                                 | URL for streaming protocols such as RTSP, RTMP, or an IP address. |

è¿™é‡Œæˆ‘åªç”¨äº†å›¾ç‰‡å’Œè§†é¢‘ã€‚

åœ¨åé¢å¦‚æœè¦å°†YOLOv8å†™åˆ°è‡ªå·±çš„è¯†åˆ«ç¨‹åºé‡Œé¢ï¼Œå°±åªèƒ½ç”¨å›¾ç‰‡é€å¸§é¢„æµ‹ã€‚ï¼ˆä¹Ÿè®¸æœ‰æ›´å¥½çš„æ–¹æ³•ä½†æˆ‘ä¸ä¼šï¼‰

```python
from ultralytics import YOLO

# é€‰å–è®­ç»ƒçš„æ¨¡å‹
model = YOLO('run/detect/train/weights/best.pt')

# è§†é¢‘é¢„æµ‹
source = 'test.mp4'
results = model(source)

# å›¾ç‰‡é¢„æµ‹
source = 'test.jpg'
results = model(source)# è¿™é‡Œè®¾ç½®save=Trueä¼šä¿å­˜ä¸€ä¸ªpredictæ–‡ä»¶åˆ° runs/detect ä¸­
```

é¢„æµ‹ç»“æœ

![image-20230713151246856](C:\Users\leesh\AppData\Roaming\Typora\typora-user-images\image-20230713151246856.png)

é¢„æµ‹çš„å…·ä½“ä¿¡æ¯

```python
# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bbox outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Class probabilities for classification outputs
```

è¿™é‡Œç›´æ¥å¯¼å…¥åˆ°supervisionæ›´å¥½ç”¨ã€‚åœ¨åé¢ä¼šç”¨åˆ°ã€‚

---

# è§†é¢‘æ£€æµ‹

åœ¨åé¢æŠŠæ¨¡å‹éƒ¨ç½²åˆ°è§†é¢‘æ£€æµ‹ç¨‹åºçš„æ—¶å€™ï¼Œè¿˜å­¦åˆ°äº†å¾ˆå¤šæœ‰ç”¨çš„ä¸œè¥¿ï¼Œåœ¨æ­¤åšä¸ªè®°å½•ã€‚è¿™ä¸ªå¯ä»¥ä½œä¸ºè§†é¢‘æ£€æµ‹çš„ä¸€ä¸ªå­¦ä¹ ç¬”è®°ã€‚

## å¤´æ–‡ä»¶

```python
import os
import supervision as sv
import cv2 as cv
from ultralytics import YOLO
```



## è§†é¢‘è¾“å…¥

æ ¹æ®è¾“å…¥å‚æ•°é€‰æ‹©è§†é¢‘çš„è¾“å…¥æ–¹å¼ã€‚

```python
if t == "video":
    # è§†é¢‘è¾“å…¥
    cap = cv.VideoCapture(d + "/Video/test.mp4")
    cap.set(cv.CAP_PROP_FPS, 30) # è®¾ç½®å‚æ•°
elif t == "camera":
    # æ‘„åƒå¤´è¾“å…¥
    cap = cv.VideoCapture(0)
    cap.set(cv.CAP_PROP_FPS, 30)
else:
    print("invalid input")
    return
```



### cv2.VideoCapture

```python
è®¾ç½®å‚æ•°
**propId**ï¼š  *parameter*    *function* 
0:CV_CAP_PROP_POS_MSEC   è§†é¢‘æ–‡ä»¶çš„å½“å‰ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
1:CV_CAP_PROP_POS_FRAMES ä¸‹ä¸€ä¸ªè¦è§£ç /æ•è·çš„å¸§çš„åŸºäº0çš„ç´¢å¼•
2:CV_CAP_PROP_POS_AVI_RATIO è§†é¢‘æ–‡ä»¶çš„ç›¸å¯¹ä½ç½®ï¼š0-å½±ç‰‡å¼€å§‹ï¼Œ1-å½±ç‰‡ç»“æŸ
3:CV_CAP_PROP_FRAME_WIDTH è§†é¢‘æµä¸­å¸§çš„å®½åº¦ã€‚
4:CV_CAP_PROP_FRAME_HEIGHT è§†é¢‘æµä¸­å¸§çš„é«˜åº¦
5:CV_CAP_PROP_FPS å¸§é€Ÿç‡
6:CV_CAP_PROP_FOURCC ç¼–è§£ç å™¨çš„4å­—ç¬¦ä»£ç 
7:CV_CAP_PROP_FRAME_COUNT è§†é¢‘æ–‡ä»¶ä¸­çš„å¸§æ•°
8:CV_CAP_PROP_FORMAT   retrieve()è¿”å›çš„Matå¯¹è±¡çš„æ ¼å¼
9:CV_CAP_PROP_MODE    åç«¯ç‰¹å®šçš„å€¼ï¼ŒæŒ‡ç¤ºå½“å‰æ•è·æ¨¡å¼
10:CV_CAP_PROP_BRIGHTNESS å›¾åƒçš„äº®åº¦ï¼ˆä»…é€‚ç”¨äºç›¸æœºï¼‰
11:CV_CAP_PROP_CONTRAST  å›¾åƒçš„å¯¹æ¯”åº¦ï¼ˆä»…é€‚ç”¨äºç›¸æœºï¼‰
12:CV_CAP_PROP_SATURATION  å›¾åƒçš„é¥±å’Œåº¦ï¼ˆä»…é€‚ç”¨äºç›¸æœºï¼‰
13:CV_CAP_PROP_HUE  å›¾åƒçš„è‰²è°ƒï¼ˆä»…é€‚ç”¨äºç›¸æœºï¼‰
14:CV_CAP_PROP_GAIN  å›¾åƒå¢ç›Šï¼ˆä»…é€‚ç”¨äºç›¸æœºï¼‰
15:CV_CAP_PROP_EXPOSURE  æ›å…‰ï¼ˆä»…é€‚ç”¨äºç›¸æœºï¼‰
16:CV_CAP_PROP_CONVERT_RGB æŒ‡ç¤ºå›¾åƒæ˜¯å¦åº”è½¬æ¢ä¸ºRGBçš„å¸ƒå°”æ ‡å¿—
17:CV_CAP_PROP_WHITE_BALANCE  ç™½å¹³è¡¡ ç›®å‰ä¸æ”¯æŒ
18:CV_CAP_PROP_RECTIFICATION ç«‹ä½“å£°æ‘„åƒæœºçš„æ ¡æ­£æ ‡å¿—

ä¾‹å¦‚ï¼š
cap=cv2.VideoCapture(1)
cap.set(3, 1920)
#cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)

```



## è½½å…¥æ¨¡å‹

```python
d = os.getcwd()
model = YOLO(d + "/runs/detect/default/weights/best.pt")
```



## è§†é¢‘å†™å‡ºï¼ˆé€å¸§å†™å…¥åˆ°è§†é¢‘æ–‡ä»¶ï¼‰

```python
# è·å–è§†é¢‘çš„å®½å’Œé«˜ï¼ˆä¸è·å–å®½å’Œé«˜ï¼Œå†™å‡ºæ—¶å¯¹åº”é”™è¯¯ä¼šæŠ¥é”™ï¼‰
width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))

# è§†é¢‘å†™å‡º
# æ–‡ä»¶ æ ¼å¼ å¸§ç‡ åˆ†è¾¨ç‡ å½©è‰²
writer = cv.VideoWriter(d + '/Video/output.mp4', cv.VideoWriter_fourcc(*'mp4v'), 30, (width, height), True)
```



## è®¾ç½®supervisionæ ‡è®°æ¡†

```python
# æ ‡è®°æ¡†å‚æ•°
    box_annotator = sv.BoxAnnotator(
        thickness=2,  # æ¡†çº¿å®½åº¦
        text_thickness=2,  # æ–‡å­—ç²—ç»†
        text_scale=1  # æ–‡å­—å¤§å°
    )
```



## While å¾ªç¯é€å¸§å¤„ç†

### è§†é¢‘åˆ‡ç‰‡ä¸ºå¸§

```python
# åˆ‡ç‰‡
ret, frame = cap.read()
```



### æœ«å¸§åˆ¤æ–­

è¿™ä¸ªä¸è¦å¿˜è®°ï¼Œå¦åˆ™æœ€åä¸€å¸§è·å–ä¸åˆ°frameä¼šå¯¼è‡´åé¢è°ƒç”¨frameçš„å‡½æ•°æŠ¥é”™ã€‚

```python
# åˆ¤æ–­æ˜¯å¦ç»“æŸ
if not ret:
    break
```



### æ¨¡å‹é¢„æµ‹

```python
# æ¨¡å‹é¢„æµ‹ï¼Œagnosticå‚æ•° Trueè¡¨ç¤ºå¤šä¸ªç±»ä¸€èµ·è®¡ç®—nmsï¼ŒFalseè¡¨ç¤ºæŒ‰ç…§ä¸åŒçš„ç±»åˆ†åˆ«è¿›è¡Œè®¡ç®—nms
# CPUï¼šdevice = 'cpu'ï¼ŒGPUï¼šdevice = 0 / device = [0,1]
result = model(frame, agnostic_nms=True, device=0)[0]
```

agnostic_nmså‚æ•°ä¸ºéæå¤§å€¼æŠ‘åˆ¶ï¼ˆNon-maximum Suppression (NMS)ï¼‰çš„ä½œç”¨ç®€å•è¯´å°±æ˜¯æ¨¡å‹æ£€æµ‹å‡ºäº†å¾ˆå¤šæ¡†ï¼Œæˆ‘åº”è¯¥ç•™å“ªäº›ã€‚

è®¾å¤‡é€‰æ‹©ç®—åŠ›æ›´é«˜è®¾å¤‡å¯ä»¥åŠ å¿«æ£€æµ‹é€Ÿåº¦ã€‚



## supervision

å…ˆæŠŠé¢„æµ‹ç»“æœå­˜å…¥supervision.Detectionsï¼Œåœ¨ç”¨detectionsç»™lablesèµ‹å€¼ï¼Œæœ€åé‡æ–°ç»˜åˆ¶frameã€‚

```python
# é¢„æµ‹ç»“æœå­˜å…¥supervision
#  xyxyï¼šboxesåæ ‡array  mask  confidenceï¼šboxeså¯¹åº”ç‰©ä½“ç½®ä¿¡åº¦  class_idï¼šboxeså¯¹åº”ç±»ç¼–å·  tracker_id
detections = sv.Detections.from_yolov8(result)

#model.model.names[id]ï¼Œè¿”å›ç¼–å·å¯¹åº”ç‰©å“ç±»çš„åç§°
labels = [
    f"{model.model.names[class_id]} {confidence:0.2f}"
    for _, _, confidence, class_id, _
    in detections
]

# ç”¨BoxAnnotatoråœ¨å¸§ä¸­æ¡†å‡ºæ£€æµ‹ç‰©å“
frame = box_annotator.annotate(
    scene=frame,  # å¸§ä½œä¸ºæ¡†é€‰èƒŒæ™¯
    detections=detections,  # detectionsè·å–boxes
    labels=labels  # labelsä¸ºboxesä¿¡æ¯
)
```



## å†™å‡ºè§†é¢‘ä»¥åŠè¾“å‡ºè§†é¢‘

```python
# å†™å…¥å¸§ æ³¨æ‰å¯ä»¥æé«˜é€Ÿåº¦
writer.write(frame)

# è¾“å‡º
cv.imshow("yolov8", frame)
```



## é€€å‡º

```python
# æ¯å¸§æ—¶é•¿ è¾“å…¥escé€€å‡º
if cv.waitKey(10) == 27:
    break
```



## é‡Šæ”¾

```python
#é‡Šæ”¾
cap.release()
writer.release()
cv.destroyAllWindows()

return
```





## å®Œæ•´ä»£ç 

```python
import os
import supervision as sv
import cv2 as cv
from ultralytics import YOLO


def animal_recognizer(t):
    d = os.getcwd()

    if t == "video":
        # è§†é¢‘è¾“å…¥
        cap = cv.VideoCapture(d + "/Video/test.mp4")
        cap.set(cv.CAP_PROP_FPS, 30)
    elif t == "camera":
        # æ‘„åƒå¤´è¾“å…¥
        cap = cv.VideoCapture(0)
        cap.set(cv.CAP_PROP_FPS, 30)
    else:
        print("invalid input")
        return

    # è½½å…¥è®­ç»ƒå®Œæˆçš„æ¨¡å‹
    model = YOLO(d + "/runs/detect/default/weights/best.pt")

    # è·å–è§†é¢‘çš„å®½å’Œé«˜
    width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))

    # è§†é¢‘å†™å‡º
    # æ–‡ä»¶ æ ¼å¼ å¸§ç‡ åˆ†è¾¨ç‡ å½©è‰²
    writer = cv.VideoWriter(d + '/Video/output.mp4', cv.VideoWriter_fourcc(*'mp4v'), 30, (width, height), True)

    # æ ‡è®°æ¡†å‚æ•°
    box_annotator = sv.BoxAnnotator(
        thickness=2,  # æ¡†çº¿å®½åº¦
        text_thickness=2,  # æ–‡å­—ç²—ç»†
        text_scale=1  # æ–‡å­—å¤§å°
    )

    while True:
        # åˆ‡ç‰‡
        ret, frame = cap.read()

        # åˆ¤æ–­æ˜¯å¦ç»“æŸ
        if not ret:
            break

        # æ¨¡å‹é¢„æµ‹ï¼Œagnosticå‚æ•° Trueè¡¨ç¤ºå¤šä¸ªç±»ä¸€èµ·è®¡ç®—nmsï¼ŒFalseè¡¨ç¤ºæŒ‰ç…§ä¸åŒçš„ç±»åˆ†åˆ«è¿›è¡Œè®¡ç®—nms
        # CPUï¼šdevice = 'cpu'ï¼ŒGPUï¼šdevice = 0 / device = [0,1]
        result = model(frame, agnostic_nms=True, device=0)[0]


        # é¢„æµ‹ç»“æœå­˜å…¥supervision
        #  xyxyï¼šboxesåæ ‡array  mask  confidenceï¼šboxeså¯¹åº”ç‰©ä½“ç½®ä¿¡åº¦  class_idï¼šboxeså¯¹åº”ç±»ç¼–å·  tracker_id
        detections = sv.Detections.from_yolov8(result)

        #model.model.names[id]ï¼Œè¿”å›ç¼–å·å¯¹åº”ç‰©å“ç±»çš„åç§°
        labels = [
            f"{model.model.names[class_id]} {confidence:0.2f}"
            for _, _, confidence, class_id, _
            in detections
        ]

        # ç”¨BoxAnnotatoråœ¨å¸§ä¸­æ¡†å‡ºæ£€æµ‹ç‰©å“
        frame = box_annotator.annotate(
            scene=frame,  # å¸§ä½œä¸ºæ¡†é€‰èƒŒæ™¯
            detections=detections,  # detectionsè·å–boxes
            labels=labels  # labelsä¸ºboxesä¿¡æ¯
        )

        # å†™å…¥å¸§ æ³¨æ‰å¯ä»¥æé«˜é€Ÿåº¦
        # writer.write(frame)

        # è¾“å‡º
        cv.imshow("yolov8", frame)

        # æ¯å¸§æ—¶é•¿ è¾“å…¥escé€€å‡º
        if cv.waitKey(10) == 27:
            break

    #é‡Šæ”¾
    cap.release()
    writer.release()
    cv.destroyAllWindows()

    return


if __name__ == '__main__':
    # animal_recognizer("video")
    animal_recognizer("camera")

   
```



# OpenVINO

[Convert and Optimize YOLOv8 with OpenVINOâ„¢](https://docs.openvino.ai/2023.0/notebooks/230-yolov8-optimization-with-output.html)

å‚ç…§ä»¥ä¸Šé“¾æ¥ï¼Œå¯¹CPUè¿è¡Œæé€Ÿè¿‘ä¸€å€ã€‚GPUçŠ¶æ€ä¸‹æé€Ÿä¸å¤ªæ˜æ˜¾ã€‚

æœªä½¿ç”¨OpenVINOï¼š

â€‹	CPU å¸§ç‡ï¼š 8.187860972310833

â€‹	GPU å¸§ç‡ï¼š16.976812571966995

ä½¿ç”¨OpenVINOï¼š

â€‹	CPU å¸§ç‡ï¼š 15.951011950592923

â€‹	GPU å¸§ç‡ï¼š 21.718895497964738

ï¼ˆåŒä¸€åœºæ™¯ä¸‹ï¼‰

â€‹	
